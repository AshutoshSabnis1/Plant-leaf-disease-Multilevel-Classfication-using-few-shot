{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d1c06723-7c6d-4a1c-8e47-2a6f9bdd449b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "from torchvision import models, transforms\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "de8d18fc-bcb7-455d-ac36-5fb0b0ba9617",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------\n",
    "# Paths and parameters\n",
    "# -----------------------\n",
    "original_base    = Path(r\"C:/plantvillage\")\n",
    "train_src        = original_base / \"train\"\n",
    "val_src          = original_base / \"val\"\n",
    "\n",
    "clean_root       = Path(r\"D:/cleaned_plantvillage\")  # New cleaned copy root\n",
    "clean_train_src  = clean_root / \"train\"\n",
    "clean_val_src    = clean_root / \"val\"\n",
    "\n",
    "fewshot_base     = Path(r\"D:/fewshot_dataset\")\n",
    "fewshot_train    = fewshot_base / \"train\"\n",
    "fewshot_val      = fewshot_base / \"val\"\n",
    "\n",
    "similarity_threshold = 0.7   # keep classes with avg_similarity >= 0.7\n",
    "k_shot               = 10    # support samples per class\n",
    "val_shot             = 10    # query samples per class\n",
    "\n",
    "# -----------------------\n",
    "# Setup device, model, transforms\n",
    "# -----------------------\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5429a13e-6560-4a03-8972-c97b5dcfe431",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EfficientNet-B0 backbone without classifier head\n",
    "backbone = models.efficientnet_b0(weights=models.EfficientNet_B0_Weights.IMAGENET1K_V1)\n",
    "backbone.classifier = torch.nn.Identity()\n",
    "backbone = backbone.to(device).eval()\n",
    "\n",
    "def get_embeddings(image_paths):\n",
    "    embs = []\n",
    "    for p in image_paths:\n",
    "        img = Image.open(p).convert(\"RGB\")\n",
    "        x = preprocess(img).unsqueeze(0).to(device)\n",
    "        with torch.no_grad():\n",
    "            feat = backbone(x)\n",
    "        feat = F.normalize(feat, p=2, dim=1)\n",
    "        embs.append(feat[0].cpu())\n",
    "    return torch.stack(embs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a20803d3-d05c-4161-99ef-347019f7ae52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------\n",
    "# 0) Prepare cleaned copy of the dataset (no deletions on original)\n",
    "# -----------------------\n",
    "if clean_root.exists():\n",
    "    shutil.rmtree(clean_root)\n",
    "clean_train_src.mkdir(parents=True, exist_ok=True)\n",
    "clean_val_src.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Copy original train and val folders into cleaned directory\n",
    "for cls_dir in sorted(train_src.iterdir()):\n",
    "    if cls_dir.is_dir():\n",
    "        shutil.copytree(cls_dir, clean_train_src / cls_dir.name)\n",
    "for cls_dir in sorted(val_src.iterdir()):\n",
    "    if cls_dir.is_dir():\n",
    "        shutil.copytree(cls_dir, clean_val_src / cls_dir.name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2db12f6b-eaf0-4b07-8243-61859f0eac9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cleaning classes: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 38/38 [2:20:59<00:00, 222.62s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Remaining classes after cleaning:\n",
      "  Apple___Cedar_apple_rust\n",
      "  Blueberry___healthy\n",
      "  Cherry_(including_sour)___healthy\n",
      "  Grape___Black_rot\n",
      "  Grape___Esca_(Black_Measles)\n",
      "  Grape___healthy\n",
      "  Grape___Leaf_blight_(Isariopsis_Leaf_Spot)\n",
      "  Potato___healthy\n",
      "  Raspberry___healthy\n",
      "  Soybean___healthy\n",
      "  Strawberry___healthy\n",
      "  Tomato___Tomato_mosaic_virus\n"
     ]
    }
   ],
   "source": [
    "# -----------------------\n",
    "# 1) Cleaning: delete classes with low intra-class similarity\n",
    "# -----------------------\n",
    "kept_classes = []\n",
    "for cls_dir in tqdm(sorted(clean_train_src.iterdir()), desc=\"Cleaning classes\"):\n",
    "    if not cls_dir.is_dir():\n",
    "        continue\n",
    "\n",
    "    imgs = [p for p in cls_dir.iterdir() if p.suffix.lower() in (\".jpg\",\".jpeg\",\".png\")]\n",
    "    if len(imgs) < 2:\n",
    "        continue\n",
    "\n",
    "    emb = get_embeddings(imgs)\n",
    "    sim_matrix = emb @ emb.t()\n",
    "    n = sim_matrix.size(0)\n",
    "    sims = sim_matrix[~torch.eye(n, dtype=torch.bool)].view(n, n-1)\n",
    "    avg_sim = sims.mean().item()\n",
    "\n",
    "    if avg_sim < similarity_threshold:\n",
    "        # delete from cleaned train and val\n",
    "        shutil.rmtree(cls_dir)\n",
    "        val_cls = clean_val_src / cls_dir.name\n",
    "        if val_cls.exists():\n",
    "            shutil.rmtree(val_cls)\n",
    "    else:\n",
    "        kept_classes.append(cls_dir.name)\n",
    "\n",
    "# -----------------------\n",
    "# 1.1) Rebuild cleaned val to contain only original val images of kept classes\n",
    "# -----------------------\n",
    "if clean_val_src.exists():\n",
    "    shutil.rmtree(clean_val_src)\n",
    "clean_val_src.mkdir(parents=True, exist_ok=True)\n",
    "for cls in kept_classes:\n",
    "    src = val_src / cls\n",
    "    if src.exists():\n",
    "        shutil.copytree(src, clean_val_src / cls)\n",
    "\n",
    "# Show remaining classes after cleaning\n",
    "print(\"\\nRemaining classes after cleaning:\")\n",
    "for name in kept_classes:\n",
    "    print(f\"  {name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d797abc8-1a36-42a7-b29f-bc54feaf24a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total images in 'D:/cleaned_plantvillage': 13135\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Set the dataset directory\n",
    "dataset_dir = r\"D:/cleaned_plantvillage\"\n",
    "\n",
    "# Function to count images in a directory (recursively)\n",
    "def count_images(root_dir, extensions=('.jpg', '.jpeg', '.png', '.bmp', '.gif')):\n",
    "    total = 0\n",
    "    for dirpath, dirnames, filenames in os.walk(root_dir):\n",
    "        total += sum(1 for file in filenames if file.lower().endswith(extensions))\n",
    "    return total\n",
    "\n",
    "# Count total images in dataset\n",
    "total_images = count_images(dataset_dir)\n",
    "\n",
    "print(f\"Total images in '{dataset_dir}': {total_images}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7914a1c0-78e9-4c2a-87de-11b3bd41661b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "17533aba-e345-4345-8b22-2b89ffc9c988",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“ Checking folder: D:\\fewshot_dataset\\train\n",
      "  Apple___Cedar_apple_rust: 10 images\n",
      "  Blueberry___healthy: 10 images\n",
      "  Cherry_(including_sour)___healthy: 10 images\n",
      "  Grape___Black_rot: 10 images\n",
      "  Grape___Esca_(Black_Measles): 10 images\n",
      "  Grape___healthy: 10 images\n",
      "  Grape___Leaf_blight_(Isariopsis_Leaf_Spot): 10 images\n",
      "  Potato___healthy: 10 images\n",
      "  Raspberry___healthy: 10 images\n",
      "  Soybean___healthy: 10 images\n",
      "  Strawberry___healthy: 10 images\n",
      "  Tomato___Tomato_mosaic_virus: 10 images\n",
      "\n",
      "ðŸ“ Checking folder: D:\\fewshot_dataset\\val\n",
      "  Apple___Cedar_apple_rust: 10 images\n",
      "  Blueberry___healthy: 10 images\n",
      "  Cherry_(including_sour)___healthy: 10 images\n",
      "  Grape___Black_rot: 10 images\n",
      "  Grape___Esca_(Black_Measles): 10 images\n",
      "  Grape___healthy: 10 images\n",
      "  Grape___Leaf_blight_(Isariopsis_Leaf_Spot): 10 images\n",
      "  Potato___healthy: 10 images\n",
      "  Raspberry___healthy: 10 images\n",
      "  Soybean___healthy: 10 images\n",
      "  Strawberry___healthy: 10 images\n",
      "  Tomato___Tomato_mosaic_virus: 10 images\n"
     ]
    }
   ],
   "source": [
    "# -----------------------\n",
    "# 2) Build few-shot splits from cleaned copy\n",
    "# -----------------------\n",
    "# Remove old few-shot directories\n",
    "for d in (fewshot_train, fewshot_val):\n",
    "    if d.exists():\n",
    "        shutil.rmtree(d)\n",
    "    d.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Helper to create few-shot dataset\n",
    "def create_fewshot_dataset(src_path, dest_path):\n",
    "    for class_folder in sorted(src_path.iterdir()):\n",
    "        if not class_folder.is_dir():\n",
    "            continue\n",
    "        images = [p for p in class_folder.iterdir() if p.suffix.lower() in (\".jpg\",\".jpeg\",\".png\")]\n",
    "        if len(images) < k_shot + val_shot:\n",
    "            print(f\"Not enough images in {class_folder.name} to sample {k_shot+val_shot}, skipping.\")\n",
    "            continue\n",
    "\n",
    "        random.shuffle(images)\n",
    "        support = images[:k_shot]\n",
    "        query   = images[k_shot:k_shot + val_shot]\n",
    "\n",
    "        # copy support images to few-shot train\n",
    "        sup_dest = dest_path / class_folder.name\n",
    "        sup_dest.mkdir(parents=True, exist_ok=True)\n",
    "        for img in support:\n",
    "            shutil.copy2(img, sup_dest / img.name)\n",
    "\n",
    "# Create few-shot train and val splits\n",
    "create_fewshot_dataset(clean_train_src, fewshot_train)\n",
    "create_fewshot_dataset(clean_val_src, fewshot_val)\n",
    "\n",
    "# -----------------------\n",
    "# 3) Verification: print counts\n",
    "# -----------------------\n",
    "def count_images(folder_path):\n",
    "    print(f\"\\nðŸ“ Checking folder: {folder_path}\")\n",
    "    for class_folder in sorted(folder_path.iterdir()):\n",
    "        if class_folder.is_dir():\n",
    "            count = len([f for f in class_folder.iterdir() if f.suffix.lower() in (\".jpg\",\".jpeg\",\".png\")])\n",
    "            print(f\"  {class_folder.name}: {count} images\")\n",
    "\n",
    "count_images(fewshot_train)\n",
    "count_images(fewshot_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c645c564-7cde-4cdd-989f-e413f91b742e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“‚ Total images in TRAIN: 120\n",
      "ðŸ“‚ Total images in VAL: 120\n",
      "ðŸ“¦ TOTAL images in FEWSHOT dataset: 240\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "fewshot_base = Path(r\"D:/fewshot_dataset\")\n",
    "\n",
    "def count_total_images(base_path):\n",
    "    totals = {}\n",
    "    for split in ['train', 'val']:\n",
    "        split_path = base_path / split\n",
    "        count = sum(len(list(folder.glob(\"*.jpg\"))) + \n",
    "                    len(list(folder.glob(\"*.jpeg\"))) + \n",
    "                    len(list(folder.glob(\"*.png\")))\n",
    "                    for folder in split_path.iterdir() if folder.is_dir())\n",
    "        totals[split] = count\n",
    "    return totals\n",
    "\n",
    "totals = count_total_images(fewshot_base)\n",
    "\n",
    "print(f\"ðŸ“‚ Total images in TRAIN: {totals['train']}\")\n",
    "print(f\"ðŸ“‚ Total images in VAL: {totals['val']}\")\n",
    "print(f\"ðŸ“¦ TOTAL images in FEWSHOT dataset: {totals['train'] + totals['val']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "693116d8-79d3-4e75-8b15-79a50416929a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import argparse\n",
    "from collections import defaultdict\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import models, transforms\n",
    "import h5py\n",
    "from torch.cuda.amp import autocast, GradScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "ba8d6a26-8c85-42f8-bad2-06130bf80214",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seeds for reproducibility\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "\n",
    "###############################################\n",
    "# Helper Functions: Save Model & Prototypes\n",
    "###############################################\n",
    "def save_model_h5(state_dict, filename):\n",
    "    with h5py.File(filename, 'w') as f:\n",
    "        grp = f.create_group(\"model\")\n",
    "        for k, v in state_dict.items():\n",
    "            grp.create_dataset(k, data=v.cpu().numpy())\n",
    "\n",
    "def save_prototypes_npy(prototypes, filename):\n",
    "    np.save(filename, prototypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "b796e2a4-256f-4079-8fca-8eeb0f2c4bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################\n",
    "# Dataset for Few-Shot\n",
    "###############################################\n",
    "class PlantDiseaseDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None, augment_factor=1):\n",
    "        self.root_dir = Path(root_dir)\n",
    "        self.transform = transform\n",
    "        self.augment_factor = augment_factor\n",
    "        self.classes, self.disease_classes = self._find_classes()\n",
    "        self.class_to_idx = {c: i for i, c in enumerate(self.classes)}\n",
    "        self.image_cache = []\n",
    "        self._load_cache()\n",
    "        self._build_indices()\n",
    "        if self.augment_factor > 1:\n",
    "            self._balance()\n",
    "\n",
    "    def _find_classes(self):\n",
    "        plants, diseases = set(), set()\n",
    "        for d in self.root_dir.iterdir():\n",
    "            if d.is_dir():\n",
    "                parts = d.name.split('___', 1)\n",
    "                if len(parts) == 2:\n",
    "                    plants.add(parts[0]); diseases.add(parts[1])\n",
    "        return sorted(plants), sorted(diseases)\n",
    "\n",
    "    def _load_cache(self):\n",
    "        for d in self.root_dir.iterdir():\n",
    "            if not d.is_dir(): continue\n",
    "            parts = d.name.split('___', 1)\n",
    "            if len(parts) != 2: continue\n",
    "            plant, disease = parts\n",
    "            if disease not in self.disease_classes: continue\n",
    "            p_lbl = self.class_to_idx[plant]\n",
    "            d_lbl = self.disease_classes.index(disease)\n",
    "            for imgf in d.iterdir():\n",
    "                if imgf.suffix.lower() in ('.jpg', '.png', '.jpeg'):\n",
    "                    img = Image.open(imgf).convert('RGB')\n",
    "                    self.image_cache.append((img, p_lbl, d_lbl))\n",
    "        print(f\"Loaded {len(self.image_cache)} images from {len(self.classes)} plants and {len(self.disease_classes)} diseases\")\n",
    "\n",
    "    def _build_indices(self):\n",
    "        self.plant_idx = defaultdict(list)\n",
    "        self.disease_idx = defaultdict(list)\n",
    "        for i, (_, p, d) in enumerate(self.image_cache):\n",
    "            self.plant_idx[p].append(i)\n",
    "            self.disease_idx[d].append(i)\n",
    "\n",
    "    def _balance(self):\n",
    "        counts = {d: len(v) for d, v in self.disease_idx.items()}\n",
    "        maxc = max(counts.values())\n",
    "        balanced = list(self.image_cache)\n",
    "        for d, c in counts.items():\n",
    "            if c < maxc:\n",
    "                choices = [x for x in self.image_cache if x[2] == d]\n",
    "                needed = (maxc - c) * self.augment_factor\n",
    "                balanced.extend(random.choices(choices, k=needed))\n",
    "        self.image_cache = balanced\n",
    "        self._build_indices()\n",
    "\n",
    "    def __len__(self): return len(self.image_cache)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img, p, d = self.image_cache[idx]\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        return img, p, d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "cc13eaea-1db8-43d7-bf62-21367cbe6498",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################\n",
    "# Prototypical Network Model\n",
    "##############################################\n",
    "class EfficientProtoNet(nn.Module):\n",
    "    def __init__(self, num_disease, emb_dim=384):\n",
    "        super().__init__()\n",
    "        backbone = models.efficientnet_b0(weights=models.EfficientNet_B0_Weights.IMAGENET1K_V1)\n",
    "        orig_cls = backbone.classifier\n",
    "        in_f = orig_cls[1].in_features if isinstance(orig_cls, nn.Sequential) else None\n",
    "        backbone.classifier = nn.Identity()\n",
    "        self.backbone = backbone\n",
    "        self.embed = nn.Sequential(\n",
    "            nn.Linear(in_f, 768), nn.ReLU(), nn.Dropout(0.7),\n",
    "            nn.Linear(768, emb_dim), nn.BatchNorm1d(emb_dim)\n",
    "        )\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Linear(emb_dim, 256), nn.ReLU(), nn.Linear(256, num_disease)\n",
    "        )\n",
    "        self.l2norm = True\n",
    "\n",
    "    def forward(self, x):\n",
    "        f = self.backbone(x)\n",
    "        e = self.embed(f)\n",
    "        if self.l2norm:\n",
    "            e = F.normalize(e, p=2, dim=1)\n",
    "        logits = self.head(e)\n",
    "        return e, logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "da06096b-f509-4bc9-9df8-83f13a95ed66",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################\n",
    "# Loss, Sampling, Prototype Extraction\n",
    "##############################################\n",
    "def enhanced_proto_loss(s_sup, l_sup, s_q, l_q, temp=20.0, ls=0.2):\n",
    "    classes = torch.unique(l_sup)\n",
    "    protos = torch.stack([s_sup[l_sup == c].mean(0) for c in classes])\n",
    "    logits = -torch.cdist(s_q, protos) * temp\n",
    "    new_lbl = torch.tensor([(classes == l).nonzero().item() for l in l_q], device=s_q.device)\n",
    "    loss = nn.CrossEntropyLoss(label_smoothing=ls)(logits, new_lbl)\n",
    "    acc = (logits.argmax(1) == new_lbl).float().mean().item()\n",
    "    return loss, acc\n",
    "\n",
    "def sample_episode(ds, task, n_way, k_shot, q_query):\n",
    "    idx_dict = ds.plant_idx if task == 'plant' else ds.disease_idx\n",
    "    classes = random.sample(list(idx_dict.keys()), n_way)\n",
    "    s_imgs, s_lbls, q_imgs, q_lbls = [], [], [], []\n",
    "    for i, c in enumerate(classes):\n",
    "        idxs = idx_dict[c]\n",
    "        total = k_shot + q_query\n",
    "        sel = random.sample(idxs, total) if len(idxs) >= total else random.choices(idxs, k=total)\n",
    "        for j, idx in enumerate(sel):\n",
    "            img, p, d = ds[idx]\n",
    "            if j < k_shot:\n",
    "                s_imgs.append(img)\n",
    "                s_lbls.append(i)\n",
    "            else:\n",
    "                q_imgs.append(img)\n",
    "                q_lbls.append(i)\n",
    "    return (torch.stack(s_imgs), torch.tensor(s_lbls)), (torch.stack(q_imgs), torch.tensor(q_lbls))\n",
    "\n",
    "def extract_prototypes(model, ds, device, n_way=5, k_shot=10, episodes=10):\n",
    "    prototype_dict = np.zeros((len(ds.disease_classes), model.embed[-1].num_features))\n",
    "    for ci in range(len(ds.disease_classes)):\n",
    "        accumulated = []\n",
    "        for _ in range(episodes):\n",
    "            indices = ds.disease_idx[ci]\n",
    "            sel = random.choices(indices, k=k_shot) if len(indices) < k_shot else random.sample(indices, k_shot)\n",
    "            imgs = torch.stack([ds[i][0] for i in sel]).to(device)\n",
    "            with torch.no_grad():\n",
    "                emb, _ = model(imgs)\n",
    "            accumulated.append(emb.mean(0).cpu().numpy())\n",
    "        prototype_dict[ci] = np.mean(accumulated, axis=0)\n",
    "    return prototype_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "7ac719e4-2d40-4212-a226-f528264b87df",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################\n",
    "# Epoch Functions\n",
    "##############################################\n",
    "def train_epoch(model, ds, opt, device, train_eps, n_way, k_shot, q_query, scaler=None):\n",
    "    model.train()\n",
    "    tloss, tacc, p_tot, d_tot, p_cnt, d_cnt = 0, 0, 0, 0, 0, 0\n",
    "    for _ in range(train_eps):\n",
    "        task = 'disease' if random.random() < 0.7 else 'plant'\n",
    "        (s_img, s_lbl), (q_img, q_lbl) = sample_episode(ds, task, n_way, k_shot, q_query)\n",
    "        s_img, s_lbl, q_img, q_lbl = [x.to(device) for x in (s_img, s_lbl, q_img, q_lbl)]\n",
    "        if scaler:\n",
    "            with autocast():\n",
    "                s_e, _ = model(s_img)\n",
    "                q_e, _ = model(q_img)\n",
    "                loss, acc = enhanced_proto_loss(s_e, s_lbl, q_e, q_lbl)\n",
    "            opt.zero_grad()\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(opt)\n",
    "            scaler.update()\n",
    "        else:\n",
    "            s_e, _ = model(s_img)\n",
    "            q_e, _ = model(q_img)\n",
    "            loss, acc = enhanced_proto_loss(s_e, s_lbl, q_e, q_lbl)\n",
    "            opt.zero_grad()\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "        tloss += loss.item()\n",
    "        tacc += acc\n",
    "        if task == 'plant':\n",
    "            p_tot += acc\n",
    "            p_cnt += 1\n",
    "        else:\n",
    "            d_tot += acc\n",
    "            d_cnt += 1\n",
    "    combined_acc = tacc / train_eps\n",
    "    plant_acc = p_tot / p_cnt if p_cnt else 0\n",
    "    disease_acc = d_tot / d_cnt if d_cnt else 0\n",
    "    return {'loss': tloss / train_eps, 'plant_acc': plant_acc, 'disease_acc': disease_acc, 'combined_acc': combined_acc}\n",
    "\n",
    "def evaluate(model, ds, device, val_eps, n_way, k_shot, q_query, scaler=None):\n",
    "    model.eval()\n",
    "    plant_acc, disease_acc = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for task in ['plant', 'disease']:\n",
    "            for _ in range(val_eps):\n",
    "                (s_img, s_lbl), (q_img, q_lbl) = sample_episode(ds, task, n_way, k_shot, q_query)\n",
    "                s_img, s_lbl, q_img, q_lbl = [x.to(device) for x in (s_img, s_lbl, q_img, q_lbl)]\n",
    "                if scaler:\n",
    "                    with autocast():\n",
    "                        s_e, _ = model(s_img)\n",
    "                        q_e, _ = model(q_img)\n",
    "                        acc = enhanced_proto_loss(s_e, s_lbl, q_e, q_lbl)[1]\n",
    "                else:\n",
    "                    s_e, _ = model(s_img)\n",
    "                    q_e, _ = model(q_img)\n",
    "                    acc = enhanced_proto_loss(s_e, s_lbl, q_e, q_lbl)[1]\n",
    "                if task == 'plant':\n",
    "                    plant_acc += acc\n",
    "                else:\n",
    "                    disease_acc += acc\n",
    "    return {'plant_acc': plant_acc / val_eps, 'disease_acc': disease_acc / val_eps, 'avg_acc': (plant_acc + disease_acc) / (2 * val_eps)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "c22f0d0f-a663-4c21-9755-943269fecfa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "Loaded 120 images from 9 plants and 6 diseases\n",
      "Loaded 120 images from 9 plants and 6 diseases\n",
      "Epoch 1/20:\n",
      "  Train Loss: 1.4206\n",
      "  Train Plant Acc: 40.33% | Train Disease Acc: 49.14% | Combined Train Acc: 46.50%\n",
      "  Val Plant Acc: 89.07% | Val Disease Acc: 93.47% | Combined Val Acc: 91.27%\n",
      "Best model and prototypes saved!\n",
      "Epoch 2/20:\n",
      "  Train Loss: 1.1427\n",
      "  Train Plant Acc: 65.00% | Train Disease Acc: 72.33% | Combined Train Acc: 69.40%\n",
      "  Val Plant Acc: 94.40% | Val Disease Acc: 96.53% | Combined Val Acc: 95.47%\n",
      "Best model and prototypes saved!\n",
      "Epoch 3/20:\n",
      "  Train Loss: 1.0142\n",
      "  Train Plant Acc: 66.00% | Train Disease Acc: 86.43% | Combined Train Acc: 80.30%\n",
      "  Val Plant Acc: 93.60% | Val Disease Acc: 94.53% | Combined Val Acc: 94.07%\n",
      "Epoch 4/20:\n",
      "  Train Loss: 0.9302\n",
      "  Train Plant Acc: 77.67% | Train Disease Acc: 91.14% | Combined Train Acc: 87.10%\n",
      "  Val Plant Acc: 91.87% | Val Disease Acc: 95.47% | Combined Val Acc: 93.67%\n",
      "Epoch 5/20:\n",
      "  Train Loss: 0.8720\n",
      "  Train Plant Acc: 74.00% | Train Disease Acc: 95.18% | Combined Train Acc: 92.00%\n",
      "  Val Plant Acc: 91.07% | Val Disease Acc: 98.53% | Combined Val Acc: 94.80%\n",
      "Epoch 6/20:\n",
      "  Train Loss: 0.8698\n",
      "  Train Plant Acc: 83.43% | Train Disease Acc: 97.54% | Combined Train Acc: 92.60%\n",
      "  Val Plant Acc: 96.13% | Val Disease Acc: 95.33% | Combined Val Acc: 95.73%\n",
      "Best model and prototypes saved!\n",
      "Epoch 7/20:\n",
      "  Train Loss: 0.8051\n",
      "  Train Plant Acc: 90.00% | Train Disease Acc: 97.29% | Combined Train Acc: 96.20%\n",
      "  Val Plant Acc: 92.67% | Val Disease Acc: 97.60% | Combined Val Acc: 95.13%\n",
      "Epoch 8/20:\n",
      "  Train Loss: 0.8178\n",
      "  Train Plant Acc: 89.60% | Train Disease Acc: 97.47% | Combined Train Acc: 95.50%\n",
      "  Val Plant Acc: 91.73% | Val Disease Acc: 95.87% | Combined Val Acc: 93.80%\n",
      "Epoch 9/20:\n",
      "  Train Loss: 0.8347\n",
      "  Train Plant Acc: 89.67% | Train Disease Acc: 96.86% | Combined Train Acc: 94.70%\n",
      "  Val Plant Acc: 94.27% | Val Disease Acc: 95.87% | Combined Val Acc: 95.07%\n",
      "Epoch 10/20:\n",
      "  Train Loss: 0.8113\n",
      "  Train Plant Acc: 92.25% | Train Disease Acc: 98.50% | Combined Train Acc: 96.00%\n",
      "  Val Plant Acc: 94.13% | Val Disease Acc: 95.07% | Combined Val Acc: 94.60%\n",
      "Epoch 11/20:\n",
      "  Train Loss: 0.8225\n",
      "  Train Plant Acc: 86.00% | Train Disease Acc: 98.31% | Combined Train Acc: 94.00%\n",
      "  Val Plant Acc: 92.53% | Val Disease Acc: 97.73% | Combined Val Acc: 95.13%\n",
      "Early stopping triggered due to no improvement\n"
     ]
    }
   ],
   "source": [
    "##############################################\n",
    "# Main Execution\n",
    "##############################################\n",
    "def main(train_dir, valid_dir, args):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Using device: {device}\")\n",
    "    set_seed(args.seed)\n",
    "    scaler = GradScaler() if device.type == 'cuda' else None\n",
    "\n",
    "    train_transform = transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224, scale=(0.65, 1.0)),\n",
    "        transforms.RandomHorizontalFlip(p=0.5),\n",
    "        transforms.ColorJitter(brightness=0.3, contrast=0.3),\n",
    "        transforms.RandomRotation(15),\n",
    "        transforms.RandomVerticalFlip(p=0.2),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406],[0.229, 0.224, 0.225]),\n",
    "        transforms.RandomErasing(p=0.2)\n",
    "    ])\n",
    "    val_transform = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406],[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "    train_ds = PlantDiseaseDataset(train_dir, train_transform, augment_factor=2)\n",
    "    val_ds   = PlantDiseaseDataset(valid_dir, val_transform)\n",
    "    model    = EfficientProtoNet(len(train_ds.disease_classes)).to(device)\n",
    "    optimizer= optim.AdamW(model.parameters(), lr=args.lr, weight_decay=5e-4)\n",
    "    scheduler= ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=3)\n",
    "\n",
    "    best_acc, patience_count, overfit_count = 0.0, 0, 0\n",
    "    for epoch in range(args.epochs):\n",
    "        train_metrics = train_epoch(model, train_ds, optimizer, device, args.train_eps, 5, 5, 10, scaler)\n",
    "        val_metrics   = evaluate(model, val_ds, device, args.val_eps, 5, 5, 15, scaler)\n",
    "        scheduler.step(val_metrics['avg_acc'])\n",
    "        gap = train_metrics['combined_acc'] - val_metrics['avg_acc']\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{args.epochs}:\")\n",
    "        print(f\"  Train Loss: {train_metrics['loss']:.4f}\")\n",
    "        print(f\"  Train Plant Acc: {train_metrics['plant_acc']:.2%} | Train Disease Acc: {train_metrics['disease_acc']:.2%} | Combined Train Acc: {train_metrics['combined_acc']:.2%}\")\n",
    "        print(f\"  Val Plant Acc: {val_metrics['plant_acc']:.2%} | Val Disease Acc: {val_metrics['disease_acc']:.2%} | Combined Val Acc: {val_metrics['avg_acc']:.2%}\")\n",
    "\n",
    "        if val_metrics['avg_acc'] > best_acc:\n",
    "            best_acc = val_metrics['avg_acc']\n",
    "            patience_count = 0\n",
    "            overfit_count = 0\n",
    "            save_model_h5(model.state_dict(), \"best_model.h5\")\n",
    "            prototypes = extract_prototypes(model, val_ds, device)\n",
    "            save_prototypes_npy(prototypes, \"prototypes.npy\")\n",
    "            print(\"Best model and prototypes saved!\")\n",
    "        else:\n",
    "            patience_count += 1\n",
    "            if gap > 0.05:\n",
    "                overfit_count += 1\n",
    "                print(f\"Warning: Overfitting suspected (gap={gap:.2%})\")\n",
    "            else:\n",
    "                overfit_count = 0\n",
    "            if patience_count >= args.patience:\n",
    "                print(\"Early stopping triggered due to no improvement\")\n",
    "                break\n",
    "            if overfit_count >= 3:\n",
    "                print(\"Early stopping triggered due to overfitting\")\n",
    "                break\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--seed', type=int, default=42)\n",
    "    parser.add_argument('--lr', type=float, default=5e-5)\n",
    "    parser.add_argument('--epochs', type=int, default=20)\n",
    "    parser.add_argument('--patience', type=int, default=5)\n",
    "    parser.add_argument('--train_eps', type=int, default=20)\n",
    "    parser.add_argument('--val_eps', type=int, default=10)\n",
    "    args, _ = parser.parse_known_args()\n",
    "    main(r\"D:/fewshot_dataset/train\", r\"D:/fewshot_dataset/val\", args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "78124ca4-608b-4d7e-a357-f3823fe009e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 103/103 [1:11:54<00:00, 41.89s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total time: 4314.5s\n",
      "=== Full-dataset metrics ===\n",
      "Accuracy:  97.77%\n",
      "Precision: 95.46%\n",
      "Recall:    96.40%\n",
      "F1 Score:  95.83%\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import models, transforms\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from tqdm import tqdm\n",
    "import h5py\n",
    "\n",
    "# 1) Dataset (same as before)\n",
    "class PlantDiseaseDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform):\n",
    "        self.transform = transform\n",
    "        self.samples, diseases = [], set()\n",
    "        for split in (\"train\",\"val\"):\n",
    "            for cls in (Path(root_dir)/split).iterdir():\n",
    "                if cls.is_dir() and \"___\" in cls.name:\n",
    "                    disease = cls.name.split(\"___\",1)[1]\n",
    "                    diseases.add(disease)\n",
    "                    for imgf in cls.iterdir():\n",
    "                        if imgf.suffix.lower() in (\".jpg\",\".jpeg\",\".png\"):\n",
    "                            self.samples.append((imgf, disease))\n",
    "        self.disease_classes = sorted(diseases)\n",
    "        self.d2i = {d:i for i,d in enumerate(self.disease_classes)}\n",
    "        self.samples = [(p, self.d2i[d]) for p,d in self.samples]\n",
    "\n",
    "    def __len__(self): return len(self.samples)\n",
    "    def __getitem__(self, idx):\n",
    "        p, lbl = self.samples[idx]\n",
    "        img = Image.open(p).convert(\"RGB\")\n",
    "        return self.transform(img), lbl\n",
    "\n",
    "# 2) Model (encoder only)\n",
    "class EfficientProtoNet(nn.Module):\n",
    "    def __init__(self, num_disease, emb_dim=384):\n",
    "        super().__init__()\n",
    "        backbone = models.efficientnet_b0(weights=models.EfficientNet_B0_Weights.IMAGENET1K_V1)\n",
    "        in_f = backbone.classifier[1].in_features\n",
    "        backbone.classifier = nn.Identity()\n",
    "        self.backbone = backbone\n",
    "        self.embed = nn.Sequential(\n",
    "            nn.Linear(in_f, 768), nn.ReLU(), nn.Dropout(0.7),\n",
    "            nn.Linear(768, emb_dim), nn.BatchNorm1d(emb_dim)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        f = self.backbone(x)\n",
    "        e = self.embed(f)\n",
    "        return F.normalize(e, p=2.0, dim=1)\n",
    "\n",
    "# 3) Load prototypes & weights\n",
    "device = torch.device(\"cpu\")\n",
    "prototypes = torch.tensor(np.load(\"prototypes.npy\"), dtype=torch.float32).to(device)\n",
    "\n",
    "\n",
    "model = EfficientProtoNet(num_disease=prototypes.shape[0]).to(device).eval()\n",
    "with h5py.File(\"best_model.h5\",'r') as f:\n",
    "    sd = {k: torch.tensor(v[()]) for k,v in f['model'].items()}\n",
    "# load encoder & embed weights\n",
    "backbone_sd = {k.replace(\"backbone.\",\"\"):v for k,v in sd.items() if k.startswith(\"backbone.\")}\n",
    "embed_sd    = {k.replace(\"embed.\",\"\"):v for k,v in sd.items() if k.startswith(\"embed.\")}\n",
    "model.backbone.load_state_dict(backbone_sd, strict=False)\n",
    "model.embed.load_state_dict(embed_sd, strict=False)\n",
    "\n",
    "# 4) Transforms & DataLoader (num_workers=0!)\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(256), transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(), transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])\n",
    "])\n",
    "ds = PlantDiseaseDataset(r\"D:/cleaned_plantvillage\", transform)\n",
    "loader = DataLoader(ds, batch_size=128, shuffle=False, num_workers=0)  # <-- must be 0 on Windows\n",
    "\n",
    "# 5) Inference with tqdm\n",
    "all_preds, all_labels = [], []\n",
    "start = time.time()\n",
    "for imgs, labels in tqdm(loader, desc=\"Inference\"):\n",
    "    emb = model(imgs.to(device))             # [B, emb_dim]\n",
    "    dists = torch.cdist(emb, prototypes)     # [B, num_classes]\n",
    "    preds = dists.argmin(dim=1).cpu().tolist()\n",
    "    all_preds.extend(preds)\n",
    "    all_labels.extend(labels)\n",
    "end = time.time()\n",
    "\n",
    "# 6) Metrics\n",
    "acc = accuracy_score(all_labels, all_preds)\n",
    "prec, rec, f1, _ = precision_recall_fscore_support(\n",
    "    all_labels, all_preds, average='macro'\n",
    ")\n",
    "\n",
    "print(f\"\\nTotal time: {end-start:.1f}s\")\n",
    "print(\"=== Full-dataset metrics ===\")\n",
    "print(f\"Accuracy:  {acc*100:.2f}%\")\n",
    "print(f\"Precision: {prec*100:.2f}%\")\n",
    "print(f\"Recall:    {rec*100:.2f}%\")\n",
    "print(f\"F1 Score:  {f1*100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1028009-52ce-4b27-9cf5-29eb3275a07c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
